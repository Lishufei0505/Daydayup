{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "237ec5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.0a0\n",
      "/home/guest1/LISHUFEI/jupyter_code/yolov5-rt-stack/yolort/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import yolort\n",
    "print(yolort.__version__)\n",
    "print(yolort.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0449d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import platform\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3333052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c0f5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/guest1/LISHUFEI/jupyter_code/yolov5-rt-stack\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "FILE = Path().resolve()\n",
    "ROOT = FILE.parents[0]  # YOLOrt root directory\n",
    "print(str(ROOT))\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "print(str(ROOT)in sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bdff03",
   "metadata": {},
   "source": [
    "### 配置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09cb02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy\n",
    "\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # PCI_BUS_ID” # 按照PCI_BUS_ID顺序从0开始排列GPU设备 \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  #设置当前使用的GPU设备仅为0号设备  设备名称为'/gpu:0'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cuda = device.type != 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe0368b",
   "metadata": {},
   "source": [
    "### 导入模型和定义的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3137e370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val11111---------------------- /home/guest1/LISHUFEI/jupyter_code/yolov5-rt-stack\n",
      "val2222---------------------- /home/guest1/LISHUFEI/jupyter_code/yolov5-rt-stack\n"
     ]
    }
   ],
   "source": [
    "from yolort.models.yolo import YOLO\n",
    "from yolort.utils import Visualizer, get_image_from_url, read_image_to_tensor, check_dataset\n",
    "from yolort.v5 import load_yolov5_model, letterbox, non_max_suppression, scale_coords, attempt_download\n",
    "from yolort.v5.utils.downloads import safe_download\n",
    "from yolort.v5.utils.dataloaders import *\n",
    "from yolort.v5.utils.general import colorstr, increment_path\n",
    "from yolort.v5.utils.torch_utils import time_sync\n",
    "from yolort.v5.utils.metrics import ConfusionMatrix, ap_per_class\n",
    "from yolort.v5.utils.val import process_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec98c28",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4c3cc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = ROOT / 'data/coco128.yaml'  # dataset.yaml path\n",
    "data = check_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22a2777b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': '../datasets/coco128', 'train': '/home/guest1/LISHUFEI/jupyter_code/datasets/coco128/images/train2017', 'val': '/home/guest1/LISHUFEI/jupyter_code/datasets/coco128/images/train2017', 'test': None, 'nc': 80, 'names': ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'], 'download': 'https://ultralytics.com/assets/coco128.zip'}\n"
     ]
    }
   ],
   "source": [
    "print(data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa4489a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_source = \"https://huggingface.co/spaces/zhiqwang/assets/resolve/main/bus.jpg\"\n",
    "# # img_source = \"https://huggingface.co/spaces/zhiqwang/assets/resolve/main/zidane.jpg\"\n",
    "# img_raw = get_image_from_url(img_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c36f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(img_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5693acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = letterbox(img_raw, new_shape=(img_size, img_size), stride=stride)[0]\n",
    "# image = read_image_to_tensor(image)\n",
    "# image = image.to(device)\n",
    "# image = image[None]\n",
    "# print(image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35a12a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 640\n",
    "stride = 64\n",
    "score_thresh = 0.25\n",
    "batch_size = 32\n",
    "nms_thresh = 0.45\n",
    "single_cls=False # treat as single-class dataset\n",
    "rect = False\n",
    "workers=8  # max dataloader workers (per RANK in DDP mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be247188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "895cb217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning '/home/guest1/LISHUFEI/jupyter_code/datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, \u001B[0m\n"
     ]
    }
   ],
   "source": [
    "#images_source = \n",
    "#我现在需要做的是不是把images/train2017的图片加载进来？\n",
    "task = 'val'\n",
    "task = task if task in ('train', 'val', 'test') else 'val'  # path to train/val/test images\n",
    "loader,dataset = create_dataloader(data[task],\n",
    "                               img_size,\n",
    "                               stride,\n",
    "                               batch_size,\n",
    "                               single_cls,\n",
    "                               rect=rect,\n",
    "                               workers=workers,\n",
    "                               prefix=colorstr(f'{task}: '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d950ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(loader)) #loader 的长度是4 128/32\n",
    "# print(len(dataset))  # 数据集的长度是128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2705767",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 1 if single_cls else int(data['nc'])  # number of classes\n",
    "seen = 0\n",
    "confusion_matrix = ConfusionMatrix(nc=nc)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e64a7d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create_dataloader的返回值是什么？\n",
    "# print(len(loader))  # batch_size num = 4\n",
    "# ime = dataset[0] # 读取到的图像是一个元组类型的  ime[2]\n",
    "# print(dataset[0])\n",
    "# print(ime[2])\n",
    "# print(type(ime[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d7809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25726851",
   "metadata": {},
   "source": [
    "### 加载模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2a8111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果项目路径下没有的话去指定的路径下下载\n",
    "model_path = 'yolov5s.pt'\n",
    "checkpoint_path = attempt_download(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53130235",
   "metadata": {},
   "source": [
    "### 加载yolov5模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afca55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_yolov5 = load_yolov5_model(checkpoint_path, fuse=True)\n",
    "# model_yolov5 = model_yolov5.to(device)\n",
    "# model_yolov5 = model_yolov5.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81a5d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_yolov5.names)  # 也可以用 data['names'] 代替"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcb5b4b",
   "metadata": {},
   "source": [
    "### 加载yolort模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39916654",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_yolort = YOLO.load_from_yolov5(\n",
    "    checkpoint_path,\n",
    "    score_thresh=score_thresh,\n",
    "    nms_thresh=nms_thresh,\n",
    "    version=\"r6.0\",\n",
    ")\n",
    "model_yolort = model_yolort.eval()\n",
    "model_yolort = model_yolort.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f9b8aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     yolort_dets = model_yolort(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fad21ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(yolort_dets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dae42185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Detection boxes with yolort:\\n{yolort_dets[0]['boxes']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee8905cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Detection scores with yolort:\\n{yolort_dets[0]['scores']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66f129eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Detection labels with yolort:\\n{yolort_dets[0]['labels']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad78a39d",
   "metadata": {},
   "source": [
    "### batch == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41857c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a990e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, im in enumerate(dataset):\n",
    "#     im_path = im[2]\n",
    "#     img_raw = cv2.imread(im_path)  # opencv set the BGR order as the default\n",
    "#     print(img_raw.shape)\n",
    "#     assert img_raw is not None, f\"Not Found Image: {im_path}\"\n",
    "#     im = letterbox(img_raw, new_shape=(img_size, img_size), stride=stride)[0]\n",
    "#     im = read_image_to_tensor(im)\n",
    "#     print(im.size())\n",
    "#     im = im.to(device)\n",
    "#     im = im[None]\n",
    "#     print(im.size())\n",
    "#     with torch.no_grad():\n",
    "#         yolort_dets = model_yolort(im)\n",
    "#         scale_coords(im.shape[2:], yolort_dets[0]['boxes'], img_raw.shape[:-1])\n",
    "#         v = Visualizer(img_raw, data['names'])\n",
    "#         # Prepare the prediction labels for the Visualizer\n",
    "#         v.draw_instance_predictions(yolort_dets[0])\n",
    "#         v.imshow(scale=0.5)\n",
    "#         print(len(yolort_dets))\n",
    "#         print(img_raw.shape[:-1])  # 原始图片的size\n",
    "#         print(im.shape[2:])\n",
    "#         print(f\"Detection results of image: {i}\")\n",
    "#         print((type(yolort_dets[0])))# 检测结果的类型是dict\n",
    "#         for key in yolort_dets[0]: \n",
    "#             print(key) #用这种方式可以查看到字典中的key值有哪些\n",
    "#             print(yolort_dets[0][key])\n",
    "#             print(yolort_dets[0][key].size())\n",
    "#         print(f\"Detection boxes with yolort:\\n{yolort_dets[0]['boxes']}\")\n",
    "#         print(f\"Detection scores with yolort:\\n{yolort_dets[0]['scores']}\")\n",
    "#         print(f\"Detection labels with yolort:\\n{yolort_dets[0]['labels']}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9eaf21e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PosixPath('/home/guest1/LISHUFEI/jupyter_code/yolov5-rt-stack/runs/val'),)\n",
      "<class 'list'> ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
      "<class 'dict'> {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "project = ROOT / 'runs/val',  # save to project/name\n",
    "print(project)\n",
    "name='exp',  # save to project/name\n",
    "print(type(data['names']),data['names'])\n",
    "names = dict(enumerate(data['names']))\n",
    "print(type(names),names)\n",
    "# Directories\n",
    "# save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run\n",
    "# (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd1a9455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/4 [00:00<?, ?it/s]                  /home/guest1/anaconda3/envs/pytorch-lsf/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/4 [00:01<?, ?it/s]                  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [29]\u001B[0m, in \u001B[0;36m<cell line: 14>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    129\u001B[0m     ap50, ap \u001B[38;5;241m=\u001B[39m ap[:, \u001B[38;5;241m0\u001B[39m], ap\u001B[38;5;241m.\u001B[39mmean(\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# AP@0.5, AP@0.5:0.95\u001B[39;00m\n\u001B[1;32m    130\u001B[0m     mp, mr, map50, \u001B[38;5;28mmap\u001B[39m \u001B[38;5;241m=\u001B[39m p\u001B[38;5;241m.\u001B[39mmean(), r\u001B[38;5;241m.\u001B[39mmean(), ap50\u001B[38;5;241m.\u001B[39mmean(), ap\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m--> 131\u001B[0m nt \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mbincount(\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mstats\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m, minlength\u001B[38;5;241m=\u001B[39mnc)  \u001B[38;5;66;03m# number of targets per class\u001B[39;00m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;66;03m# Print results\u001B[39;00m\n\u001B[1;32m    134\u001B[0m pf \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%20s\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%11i\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%11.3g\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m4\u001B[39m  \u001B[38;5;66;03m# print format\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "#half &= device.type != 'cpu'  # FP16  # FP16 supported on limited backends with CUDA\n",
    "half = False\n",
    "plots = False\n",
    "\n",
    "jdict, stats, ap, ap_class = [], [], [], []\n",
    "s =('%20s' + '%11s' * 6) %  ('Class', 'Images', 'Labels', 'P', 'R', 'mAP@.5', 'mAP@.5:.95')\n",
    "# print(s)\n",
    "pbar = tqdm(loader, desc=s, bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')  # progress bar\n",
    "# print(type(pbar))\n",
    "dt, p, r, f1, mp, mr, map50, map = [0.0, 0.0, 0.0], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "iouv = torch.linspace(0.5, 0.95, 10, device=device)  # iou vector for mAP@0.5:0.95\n",
    "niou = iouv.numel()\n",
    "\n",
    "for batch_i, (im, targets, paths, shapes) in enumerate(pbar):\n",
    "#     print(\"batch: \", batch_i)\n",
    "    t1 = time_sync()\n",
    "#     print(\"----------1111----------\")\n",
    "#     print(shapes[0])\n",
    "#     print(\"shapes:\",len(shapes[0]))\n",
    "#     print(targets.size())\n",
    "    if cuda:\n",
    "        im = im.to(device)   # im  待检测的图片\n",
    "        targets = targets.to(device) # target 是标签么\n",
    "#         print(\"targets:\",targets)\n",
    "#         print(\"paths:\", paths)\n",
    "    im = im.half() if half else im.float()  # uint8 to fp16/32\n",
    "    im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "    nb, _, height, width = im.shape  # batch size, channels, height, width\n",
    "    t2 = time_sync()\n",
    "    dt[0] += t2 - t1\n",
    "#     print(\"--------------------22222-----------------------\")\n",
    "#     print(\"shapes:\",shapes)\n",
    "\n",
    "    yolort_dets = model_yolort(im)\n",
    "    \n",
    "    \n",
    "#     print(yolort_dets)\n",
    "  # Metrics\n",
    "    for si, pred in enumerate(yolort_dets):\n",
    "#         print(\"si:\",si)\n",
    "#         print(\"pred:\",pred)\n",
    "#        print(\"zheshisha?\",targets[:, 0])#  这是类别\n",
    "#         print(\"targets:\",targets)\n",
    "        labels = targets[targets[:, 0] == si, 1:]   # 这个batch 中的检测框信息  5维度\n",
    "#         print(\"labels:\",labels, type(labels), labels.size(), labels.shape[0])\n",
    "#         print(\"pred：\", pred)\n",
    "#         print(\"predlen：\", len(pred))\n",
    "        \n",
    "        nl, npr = labels.shape[0], len(pred)  # number of labels, predictions  \n",
    "        path, shape = Path(paths[si]), shapes[si][0]\n",
    "        correct = torch.zeros(npr, niou, dtype=torch.bool, device=device)  # init\n",
    "        seen += 1\n",
    "\n",
    "        if npr == 0:\n",
    "            if nl:\n",
    "                stats.append((correct, *torch.zeros((2, 0), device=device), labels[:, 0]))\n",
    "                if plots:\n",
    "                     confusion_matrix.process_batch(detections=None, labels=labels[:, 0])\n",
    "            continue\n",
    "\n",
    "        # Predictions\n",
    "        if single_cls:\n",
    "            pred[:, 5] = 0\n",
    "#         predn = pred[\"boxes\"].clone()\n",
    "       # detections (Array[N, 6]), x1, y1, x2, y2, conf, class  \n",
    "        predn =pred.copy()\n",
    "#         print(\"shapes[si]:\",shapes[si])\n",
    "#         print(\"im[si].shape[1:]:\",im[si].shape[1:])\n",
    "#         print(\"prednboxes:\",predn[\"boxes\"])\n",
    "#         print(\"shape:\", shape)\n",
    "#         print(\"shapes[si][1]: \", shapes[si][1])\n",
    "        scale_coords(im[si].shape[1:], predn[\"boxes\"], shape, shapes[si][1])  # native-space pre\n",
    "      \n",
    "\n",
    " # Evaluate\n",
    "        if nl:\n",
    "            tbox = xywhn2xyxy(labels[:, 1:5])  # target boxes   # xy xy    目标框  这里没问题\n",
    "           \n",
    "            tbox1 = labels[:, 1:5]   # xy wh  格式 \n",
    "#             conf = pred[\"scores\"]\n",
    "#             print(\"-----conf------:\",conf, type(conf),conf.size())\n",
    "       \n",
    "#             print(labels[:, 0:1])\n",
    "#             print(\"tbox:\", tbox)  \n",
    "#             print(\"tbox1:\", tbox1)   \n",
    "#             print(conf)\n",
    "            scale_coords(im[si].shape[1:], tbox, shape, shapes[si][1])  # native-space labels  \n",
    "            #这里出问题了，传进去的还是正常的，出来了之后就有两列变成了0\n",
    "           \n",
    "            labelsn = torch.cat((labels[:, 0:1], tbox), 1)  # native-space labels  拼接 标签和检测框\n",
    "\n",
    "#             print(predn[\"boxes\"], predn[\"boxes\"].size())\n",
    "#             print(pred[\"scores\"], pred[\"scores\"].size())\n",
    "#             print(pred[\"labels\"], pred[\"labels\"].size())\n",
    "#             pred[\"labels\"].reshape(pred[\"scores\"].size(),)\n",
    "#             print(pred[\"labels\"].unsqueeze(-1).shape)\n",
    "            predn = torch.cat((predn[\"boxes\"],predn[\"scores\"].unsqueeze(-1),predn[\"labels\"].unsqueeze(-1)),1)\n",
    "#             print(\"拼接后的结果：\")\n",
    "#             print(\"predn\", predn)\n",
    "#             print(\"labelsn:\", labelsn)\n",
    "            correct = process_batch(predn, labelsn, iouv)\n",
    "#             print(\"correct：\", correct)\n",
    "#             if plots:\n",
    "#                 confusion_matrix.process_batch(predn, labelsn)\n",
    "        stats.append((correct, pred['scores'], pred['labels'], labels[:, 0]))  # (correct, conf, pcls, tcls)\n",
    "#         print(\"stats:\", type(stats))   stats 是list 类型的\n",
    "        \n",
    "#     for x in zip(*stats):\n",
    "#         print(\"xxxx:\", type(x),x)  #tuple  元组类型\n",
    "    \n",
    "     # Compute metrics\n",
    "#     stats = [torch.cat(x, 0) for x in zip(*stats)]  # to numpy\n",
    "# #     print(\"stats类型：\",type(stats))\n",
    "#     for x in zip(*stats):\n",
    "#         for z in x:\n",
    "#             z.cpu().detach().numpy()\n",
    "    \n",
    "    stats = [torch.from_numpy(torch.cat(x, 0).cpu().detach().numpy()) for x in zip(*stats)]  # to numpy\n",
    "#     stats = [x.cpu().detach().numpy() for x in zip(*stats)]\n",
    "#     stats = [torch.cat(x, 0) for x in zip(*stats)]  # to numpy\n",
    "#     print(\"执行过了\")\n",
    "#     for i,v in enumerate(zip(*stats)):\n",
    "#         stats = torch.cat(v,0)\n",
    "        \n",
    "#     \n",
    "#     print(\"stas类型:\", type(stats[0]))\n",
    "    if len(stats) and stats[0].any():\n",
    "        tp, fp, p, r, f1, ap, ap_class = ap_per_class(*stats, plot=plots, save_dir=None, names=names)\n",
    "        ap50, ap = ap[:, 0], ap.mean(1)  # AP@0.5, AP@0.5:0.95\n",
    "        mp, mr, map50, map = p.mean(), r.mean(), ap50.mean(), ap.mean()\n",
    "    nt = np.bincount(int(stats[3]), minlength=nc)  # number of targets per class\n",
    "\n",
    "    # Print results\n",
    "    pf = '%20s' + '%11i' * 2 + '%11.3g' * 4  # print format\n",
    "    LOGGER.info(pf % ('all', seen, nt.sum(), mp, mr, map50, map))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b217b68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# s =('%20s' + '%11s' * 6) %  ('Class', 'Images', 'Labels', 'P', 'R', 'mAP@.5', 'mAP@.5:.95')\n",
    "# # print(s)\n",
    "# pbar = tqdm(loader, desc=s, bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')  # progress bar\n",
    "# # print(type(pbar))\n",
    "\n",
    "# for batch_i, (im, targets, paths, shapes) in enumerate(pbar):\n",
    "# #     print(type(im)) # Tensor 类\n",
    "# #     print(im.size())  # N ,C, H, W\n",
    "# #     im = np.ascontiguousarray(im)\n",
    "# #     print(type(im)) # numpy.ndarray 类\n",
    "# #     print(im.shape)  # N ,C, H, W\n",
    "# #     im = im.transpose((0,3,1,2))\n",
    "# #     im = cv2.cvtColor(im, cv2.COLOR_RGB2BGR) # cv2只能处理GBR格式图片\n",
    "# #     print(im.shape)  # 从这开始和想要的不一样了\n",
    "# #     im = letterbox(im, new_shape=(img_size, img_size), stride=stride)[0]  # lettebox需要的图像是np.ndarray类型的\n",
    "# #     im = Image.fromarray(cv2.cvtColor(im,cv2.COLOR_BGR2RGB))\n",
    "#     if cuda:\n",
    "# #         print(type(im)) # 每个 和 paths 中都存储了32张图片的信息，\n",
    "# #         print(len(im))\n",
    "# #         print(len(paths)) \n",
    "# #         print(type(paths)) # path 是 list 类型的， 长度为32\n",
    "# #         im = read_image_to_tensor(im) \n",
    "# #         print(im.size())\n",
    "#         im = im.to(device)\n",
    "#         targets = targets.to(device)\n",
    "#     yolort_dets = model_yolort(im)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f17a467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f73d75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db3fb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e07772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c865befb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779c8c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f520aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}