{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "237ec5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.0a0\n",
      "/home/guest1/LISHUFEI/jupyter_code/yolov5-rt-stack/yolort/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import yolort\n",
    "print(yolort.__version__)\n",
    "print(yolort.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0449d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import platform\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3333052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c0f5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/guest1/LISHUFEI/jupyter_code/yolov5-rt-stack\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "FILE = Path().resolve()\n",
    "ROOT = FILE.parents[0]  # YOLOrt root directory\n",
    "print(str(ROOT))\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "print(str(ROOT)in sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bdff03",
   "metadata": {},
   "source": [
    "### 配置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09cb02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # PCI_BUS_ID” # 按照PCI_BUS_ID顺序从0开始排列GPU设备 \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  #设置当前使用的GPU设备仅为0号设备  设备名称为'/gpu:0'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe0368b",
   "metadata": {},
   "source": [
    "### 导入模型和定义的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3137e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolort.models.yolo import YOLO\n",
    "from yolort.utils import Visualizer, get_image_from_url, read_image_to_tensor, check_dataset\n",
    "from yolort.v5 import load_yolov5_model, letterbox, non_max_suppression, scale_coords, attempt_download\n",
    "from yolort.v5.utils.downloads import safe_download\n",
    "from yolort.v5.utils.dataloaders import *\n",
    "from yolort.v5.utils.general import colorstr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec98c28",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4c3cc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = ROOT / 'data/coco128.yaml'  # dataset.yaml path\n",
    "data = check_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22a2777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa4489a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_source = \"https://huggingface.co/spaces/zhiqwang/assets/resolve/main/bus.jpg\"\n",
    "# img_source = \"https://huggingface.co/spaces/zhiqwang/assets/resolve/main/zidane.jpg\"\n",
    "img_raw = get_image_from_url(img_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c36f880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[122 148 172]\n",
      "  [120 146 170]\n",
      "  [125 153 177]\n",
      "  ...\n",
      "  [157 170 184]\n",
      "  [158 171 185]\n",
      "  [158 171 185]]\n",
      "\n",
      " [[127 153 177]\n",
      "  [124 150 174]\n",
      "  [127 155 179]\n",
      "  ...\n",
      "  [158 171 185]\n",
      "  [159 172 186]\n",
      "  [159 172 186]]\n",
      "\n",
      " [[128 154 178]\n",
      "  [126 152 176]\n",
      "  [126 154 178]\n",
      "  ...\n",
      "  [158 171 185]\n",
      "  [158 171 185]\n",
      "  [158 171 185]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[185 185 191]\n",
      "  [182 182 188]\n",
      "  [179 179 185]\n",
      "  ...\n",
      "  [114 107 112]\n",
      "  [115 105 111]\n",
      "  [116 106 112]]\n",
      "\n",
      " [[157 157 163]\n",
      "  [180 180 186]\n",
      "  [185 186 190]\n",
      "  ...\n",
      "  [107  97 103]\n",
      "  [102  92  98]\n",
      "  [108  98 104]]\n",
      "\n",
      " [[112 112 118]\n",
      "  [160 160 166]\n",
      "  [169 170 174]\n",
      "  ...\n",
      "  [ 99  89  95]\n",
      "  [ 96  86  92]\n",
      "  [102  92  98]]]\n"
     ]
    }
   ],
   "source": [
    "print(img_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5693acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = letterbox(img_raw, new_shape=(img_size, img_size), stride=stride)[0]\n",
    "# image = read_image_to_tensor(image)\n",
    "# image = image.to(device)\n",
    "# image = image[None]\n",
    "# print(image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35a12a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 640\n",
    "stride = 64\n",
    "score_thresh = 0.25\n",
    "batch_size = 32\n",
    "nms_thresh = 0.45\n",
    "single_cls=False # treat as single-class dataset\n",
    "rect = False\n",
    "workers=6  # max dataloader workers (per RANK in DDP mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be247188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "895cb217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/guest1/LISHUFEI/jupyter_code/datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#images_source = \n",
    "#我现在需要做的是不是把images/train2017的图片加载进来？\n",
    "task = 'val'\n",
    "task = task if task in ('train', 'val', 'test') else 'val'  # path to train/val/test images\n",
    "loader,dataset = create_dataloader(data[task],\n",
    "                               img_size,\n",
    "                               stride,\n",
    "                               batch_size,\n",
    "                               single_cls,\n",
    "                               rect=rect,\n",
    "                               workers=workers,\n",
    "                               prefix=colorstr(f'{task}: '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d950ec1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e64a7d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(tensor([[[114, 114, 114,  ..., 114, 114, 114],\n",
      "         [114, 114, 114,  ..., 114, 114, 114],\n",
      "         [114, 114, 114,  ..., 114, 114, 114],\n",
      "         ...,\n",
      "         [114, 114, 114,  ..., 114, 114, 114],\n",
      "         [114, 114, 114,  ..., 114, 114, 114],\n",
      "         [114, 114, 114,  ..., 114, 114, 114]],\n",
      "\n",
      "        [[114, 114, 114,  ..., 114, 114, 114],\n",
      "         [114, 114, 114,  ..., 114, 114, 114],\n",
      "         [114, 114, 114,  ..., 114, 114, 114],\n",
      "         ...,\n",
      "         [114, 114, 114,  ..., 114, 114, 114],\n",
      "         [114, 114, 114,  ..., 114, 114, 114],\n",
      "         [114, 114, 114,  ..., 114, 114, 114]],\n",
      "\n",
      "        [[114, 114, 114,  ..., 114, 114, 114],\n",
      "         [114, 114, 114,  ..., 114, 114, 114],\n",
      "         [114, 114, 114,  ..., 114, 114, 114],\n",
      "         ...,\n",
      "         [114, 114, 114,  ..., 114, 114, 114],\n",
      "         [114, 114, 114,  ..., 114, 114, 114],\n",
      "         [114, 114, 114,  ..., 114, 114, 114]]], dtype=torch.uint8), tensor([[ 0.00000, 45.00000,  0.47949,  0.64158,  0.95561,  0.44662],\n",
      "        [ 0.00000, 45.00000,  0.73652,  0.31039,  0.49888,  0.35731],\n",
      "        [ 0.00000, 50.00000,  0.63706,  0.67470,  0.49412,  0.38294],\n",
      "        [ 0.00000, 45.00000,  0.33944,  0.43917,  0.67888,  0.58613],\n",
      "        [ 0.00000, 49.00000,  0.64684,  0.22441,  0.11805,  0.07270],\n",
      "        [ 0.00000, 49.00000,  0.77315,  0.22235,  0.09073,  0.07292],\n",
      "        [ 0.00000, 49.00000,  0.66830,  0.29518,  0.13128,  0.11017],\n",
      "        [ 0.00000, 49.00000,  0.64286,  0.18441,  0.14806,  0.11105]]), '/home/guest1/LISHUFEI/jupyter_code/datasets/coco128/images/train2017/000000000009.jpg', ((480, 640), ((1.0, 1.0), (0.0, 80.0))))\n",
      "/home/guest1/LISHUFEI/jupyter_code/datasets/coco128/images/train2017/000000000009.jpg\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# create_dataloader的返回值是什么？\n",
    "print(len(loader))  # batch_size num = 4\n",
    "ime = dataset[0] # 读取到的图像是一个元组类型的  ime[2]\n",
    "print(dataset[0])\n",
    "print(ime[2])\n",
    "print(type(ime[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d7809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25726851",
   "metadata": {},
   "source": [
    "### 加载模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2a8111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果项目路径下没有的话去指定的路径下下载\n",
    "model_path = 'yolov5s.pt'\n",
    "checkpoint_path = attempt_download(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcb5b4b",
   "metadata": {},
   "source": [
    "### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39916654",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_yolort = YOLO.load_from_yolov5(\n",
    "    checkpoint_path,\n",
    "    score_thresh=score_thresh,\n",
    "    nms_thresh=nms_thresh,\n",
    "    version=\"r6.0\",\n",
    ")\n",
    "model_yolort = model_yolort.eval()\n",
    "model_yolort = model_yolort.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a990e428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 512, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest1/anaconda3/envs/pytorch-lsf/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 640, 512])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 640, 512])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 640, 512])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 640, 448])\n",
      "torch.Size([1, 3, 640, 576])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 640, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 640, 512])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 640, 448])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 576, 640])\n",
      "torch.Size([1, 3, 640, 512])\n",
      "torch.Size([1, 3, 576, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 640, 512])\n",
      "torch.Size([1, 3, 640, 448])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 576, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 640, 512])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 640, 640])\n",
      "torch.Size([1, 3, 640, 448])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 640, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 384, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 256, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 640, 512])\n",
      "torch.Size([1, 3, 640, 512])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 640, 448])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 640, 640])\n",
      "torch.Size([1, 3, 640, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 640, 640])\n",
      "torch.Size([1, 3, 640, 448])\n",
      "torch.Size([1, 3, 640, 384])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 384, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 640, 448])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 640, 512])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 640, 576])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 256, 640])\n",
      "torch.Size([1, 3, 640, 448])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 640, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 640, 384])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 640, 448])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 640, 448])\n",
      "torch.Size([1, 3, 640, 576])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 640, 448])\n",
      "torch.Size([1, 3, 576, 640])\n",
      "torch.Size([1, 3, 640, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 640, 576])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 256, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 640, 512])\n",
      "torch.Size([1, 3, 640, 512])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 640, 448])\n",
      "torch.Size([1, 3, 640, 512])\n",
      "torch.Size([1, 3, 448, 640])\n",
      "torch.Size([1, 3, 512, 640])\n",
      "torch.Size([1, 3, 448, 640])\n"
     ]
    }
   ],
   "source": [
    "for i, im in enumerate(dataset):\n",
    "    im_path = im[2]\n",
    "    img_raw = cv2.imread(im_path)  # opencv set the BGR order as the default\n",
    "    assert img_raw is not None, f\"Not Found Image: {im_path}\"\n",
    "    im = letterbox(img_raw, new_shape=(img_size, img_size), stride=stride)[0]\n",
    "    im = read_image_to_tensor(im)\n",
    "    im = im.to(device)\n",
    "    im = im[None]\n",
    "    print(im.size())\n",
    "    with torch.no_grad():\n",
    "        yolort_dets = model_yolort(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1a9455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b217b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/coco128\n"
     ]
    }
   ],
   "source": [
    "print(data[\"path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f17a467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f73d75a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
